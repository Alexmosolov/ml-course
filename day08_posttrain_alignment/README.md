PEFT:
- [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/girafe-ai/ml-course/blob/24s_harbour_dlia/day08_posttrain_alignment/practice_peft.ipynb)

**Further readings**:

- [Rotary embeddings](https://blog.eleuther.ai/rotary-embeddings/)
- [ALiBi embeddings](https://arxiv.org/abs/2305.14314)
- [IA3](https://arxiv.org/abs/2205.05638)
- [The Power of Scale for Parameter-Efficient Prompt Tuning](https://aclanthology.org/2021.emnlp-main.243.pdf)
- [P-tuning](https://arxiv.org/pdf/2103.10385.pdf)
- [Prefix-Tuning: Optimizing Continuous Prompts for Generation](https://arxiv.org/pdf/2101.00190.pdf)
- [LoRA](https://arxiv.org/abs/2106.09685)
- [QLoRA](https://arxiv.org/abs/2305.14314)