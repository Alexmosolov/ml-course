{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on [official catboost tutorials](https://github.com/catboost/tutorials/tree/master)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from catboost import CatBoostClassifier, Pool, metrics, cv\n",
    "from sklearn.metrics import accuracy_score\n",
    "from catboost import datasets\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df = datasets.titanic()\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Feature Preparation*\n",
    "\n",
    "First of all let's check how many absent values do we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age         177\n",
       "Cabin       687\n",
       "Embarked      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_value_stats = train_df.isnull().sum(axis=0)\n",
    "null_value_stats[null_value_stats != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, `Age`, `Cabin` and `Embarked` indeed have some missing values, so let's fill them with some number way out of their distributions - so the model would be able to easily distinguish between them and take it into account:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.fillna(-999, inplace=True)\n",
    "test_df.fillna(-999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop('Survived', axis=1)\n",
    "y = train_df.Survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pay attention that our features are of different types - some of them are numeric, some are categorical, and some are even just strings, which normally should be handled in some specific way (for example encoded with bag-of-words representation).\n",
    "\n",
    "But in our case we could treat these string features just as categorical one - all the heavy lifting is done inside CatBoost. How cool is that? :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n",
      "Num categorical features: 9\n"
     ]
    }
   ],
   "source": [
    "print(X.dtypes)\n",
    "\n",
    "categorical_features_indices = np.where(X.dtypes != float)[0]\n",
    "print(f\"Num categorical features: {len(categorical_features_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, train_size=0.75, random_state=42)\n",
    "\n",
    "X_test = test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Model Training*\n",
    "\n",
    "Now let's create the model itself. We will go here with default parameters, as they provide a really good baseline almost all the time. The only thing we would like to specify here is custom_loss parameter, as this would give us an ability to see what's going on in terms of this competition metric - accuracy, as well as to be able to watch for logloss, as it would be more smooth on dataset of such size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(\n",
    "    custom_loss=[metrics.Accuracy()],\n",
    "    random_seed=42,\n",
    "    logging_level='Silent'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eac6a9fdd5245cba5f7271cd607a0cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=categorical_features_indices,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    # logging_level='Verbose',  # you can uncomment this for text output\n",
    "    plot=True\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Model Cross-Validation*\n",
    "\n",
    "It is good to validate your model, but to cross-validate it - even better. And also with plots! So with no more words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e39b5f2eb4b447eb1caab430c2abec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv_params = model.get_params()\n",
    "cv_params.update({\n",
    "    'loss_function': metrics.Logloss()\n",
    "})\n",
    "cv_data = cv(\n",
    "    Pool(X, y, cat_features=categorical_features_indices),\n",
    "    cv_params,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterations</th>\n",
       "      <th>test-Logloss-mean</th>\n",
       "      <th>test-Logloss-std</th>\n",
       "      <th>train-Logloss-mean</th>\n",
       "      <th>train-Logloss-std</th>\n",
       "      <th>test-Accuracy-mean</th>\n",
       "      <th>test-Accuracy-std</th>\n",
       "      <th>train-Accuracy-mean</th>\n",
       "      <th>train-Accuracy-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.676936</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.676477</td>\n",
       "      <td>0.003152</td>\n",
       "      <td>0.794613</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>0.798541</td>\n",
       "      <td>0.020778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.660661</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>0.659381</td>\n",
       "      <td>0.003172</td>\n",
       "      <td>0.795735</td>\n",
       "      <td>0.030365</td>\n",
       "      <td>0.812009</td>\n",
       "      <td>0.010286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.646543</td>\n",
       "      <td>0.001920</td>\n",
       "      <td>0.645228</td>\n",
       "      <td>0.004168</td>\n",
       "      <td>0.803591</td>\n",
       "      <td>0.028636</td>\n",
       "      <td>0.812009</td>\n",
       "      <td>0.014119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.632857</td>\n",
       "      <td>0.003376</td>\n",
       "      <td>0.631048</td>\n",
       "      <td>0.004247</td>\n",
       "      <td>0.804714</td>\n",
       "      <td>0.026725</td>\n",
       "      <td>0.812570</td>\n",
       "      <td>0.012179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.619750</td>\n",
       "      <td>0.004936</td>\n",
       "      <td>0.617523</td>\n",
       "      <td>0.005041</td>\n",
       "      <td>0.803591</td>\n",
       "      <td>0.026153</td>\n",
       "      <td>0.813692</td>\n",
       "      <td>0.011459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>0.454106</td>\n",
       "      <td>0.056041</td>\n",
       "      <td>0.122992</td>\n",
       "      <td>0.010388</td>\n",
       "      <td>0.820426</td>\n",
       "      <td>0.016947</td>\n",
       "      <td>0.976992</td>\n",
       "      <td>0.003504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>0.454059</td>\n",
       "      <td>0.056043</td>\n",
       "      <td>0.122951</td>\n",
       "      <td>0.010359</td>\n",
       "      <td>0.820426</td>\n",
       "      <td>0.016947</td>\n",
       "      <td>0.976992</td>\n",
       "      <td>0.003504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>0.453869</td>\n",
       "      <td>0.055734</td>\n",
       "      <td>0.122882</td>\n",
       "      <td>0.010412</td>\n",
       "      <td>0.820426</td>\n",
       "      <td>0.016947</td>\n",
       "      <td>0.976992</td>\n",
       "      <td>0.003504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>0.453916</td>\n",
       "      <td>0.055660</td>\n",
       "      <td>0.122825</td>\n",
       "      <td>0.010381</td>\n",
       "      <td>0.820426</td>\n",
       "      <td>0.016947</td>\n",
       "      <td>0.976992</td>\n",
       "      <td>0.003504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>0.453880</td>\n",
       "      <td>0.055699</td>\n",
       "      <td>0.122799</td>\n",
       "      <td>0.010380</td>\n",
       "      <td>0.820426</td>\n",
       "      <td>0.016947</td>\n",
       "      <td>0.976992</td>\n",
       "      <td>0.003504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     iterations  test-Logloss-mean  test-Logloss-std  train-Logloss-mean  \\\n",
       "0             0           0.676936          0.001133            0.676477   \n",
       "1             1           0.660661          0.000697            0.659381   \n",
       "2             2           0.646543          0.001920            0.645228   \n",
       "3             3           0.632857          0.003376            0.631048   \n",
       "4             4           0.619750          0.004936            0.617523   \n",
       "..          ...                ...               ...                 ...   \n",
       "995         995           0.454106          0.056041            0.122992   \n",
       "996         996           0.454059          0.056043            0.122951   \n",
       "997         997           0.453869          0.055734            0.122882   \n",
       "998         998           0.453916          0.055660            0.122825   \n",
       "999         999           0.453880          0.055699            0.122799   \n",
       "\n",
       "     train-Logloss-std  test-Accuracy-mean  test-Accuracy-std  \\\n",
       "0             0.003152            0.794613           0.003367   \n",
       "1             0.003172            0.795735           0.030365   \n",
       "2             0.004168            0.803591           0.028636   \n",
       "3             0.004247            0.804714           0.026725   \n",
       "4             0.005041            0.803591           0.026153   \n",
       "..                 ...                 ...                ...   \n",
       "995           0.010388            0.820426           0.016947   \n",
       "996           0.010359            0.820426           0.016947   \n",
       "997           0.010412            0.820426           0.016947   \n",
       "998           0.010381            0.820426           0.016947   \n",
       "999           0.010380            0.820426           0.016947   \n",
       "\n",
       "     train-Accuracy-mean  train-Accuracy-std  \n",
       "0               0.798541            0.020778  \n",
       "1               0.812009            0.010286  \n",
       "2               0.812009            0.014119  \n",
       "3               0.812570            0.012179  \n",
       "4               0.813692            0.011459  \n",
       "..                   ...                 ...  \n",
       "995             0.976992            0.003504  \n",
       "996             0.976992            0.003504  \n",
       "997             0.976992            0.003504  \n",
       "998             0.976992            0.003504  \n",
       "999             0.976992            0.003504  \n",
       "\n",
       "[1000 rows x 9 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation accuracy score: 0.83±0.02 on step 528\n"
     ]
    }
   ],
   "source": [
    "print('Best validation accuracy score: {:.2f}±{:.2f} on step {}'.format(\n",
    "    np.max(cv_data['test-Accuracy-mean']),\n",
    "    cv_data['test-Accuracy-std'][np.argmax(cv_data['test-Accuracy-mean'])],\n",
    "    np.argmax(cv_data['test-Accuracy-mean'])\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Model Applying*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 1 0 1 0]\n",
      "[[0.8501 0.1499]\n",
      " [0.7579 0.2421]\n",
      " [0.8753 0.1247]\n",
      " [0.8782 0.1218]\n",
      " [0.2907 0.7093]\n",
      " [0.8921 0.1079]\n",
      " [0.337  0.663 ]\n",
      " [0.7877 0.2123]\n",
      " [0.3932 0.6068]\n",
      " [0.9494 0.0506]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions_probs = model.predict_proba(X_test)\n",
    "print(predictions[:10])\n",
    "print(predictions_probs[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**More features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define some params and create Pool for more convenience. It stores all information about dataset (features, labeles, categorical features indices, weights and and much more)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'iterations': 500,\n",
    "    'learning_rate': 0.1,\n",
    "    'eval_metric': metrics.Accuracy(),\n",
    "    'random_seed': 42,\n",
    "    'logging_level': 'Silent',\n",
    "    'use_best_model': False\n",
    "}\n",
    "train_pool = Pool(X_train, y_train, cat_features=categorical_features_indices)\n",
    "validate_pool = Pool(X_validation, y_validation, cat_features=categorical_features_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Early Stopping*\n",
    "\n",
    "If you essentially have a validation set, it's always easier and better to use early stopping. This feature is similar to the previous one, but only in addition to improving the quality it still saves time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.59 s, sys: 2.23 s, total: 6.81 s\n",
      "Wall time: 1.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = CatBoostClassifier(**params)\n",
    "model.fit(train_pool, eval_set=validate_pool);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 456 ms, sys: 232 ms, total: 688 ms\n",
      "Wall time: 165 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "earlystop_params = params.copy()\n",
    "earlystop_params.update({\n",
    "    'od_type': 'Iter',\n",
    "    'od_wait': 40\n",
    "})\n",
    "earlystop_model = CatBoostClassifier(**earlystop_params)\n",
    "earlystop_model.fit(train_pool, eval_set=validate_pool);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple model tree count: 500\n",
      "Simple model validation accuracy: 0.7848\n",
      "\n",
      "Early-stopped model tree count: 64\n",
      "Early-stopped model validation accuracy: 0.8117\n"
     ]
    }
   ],
   "source": [
    "print('Simple model tree count: {}'.format(model.tree_count_))\n",
    "print('Simple model validation accuracy: {:.4}'.format(\n",
    "    accuracy_score(y_validation, model.predict(X_validation))\n",
    "))\n",
    "print('')\n",
    "\n",
    "print('Early-stopped model tree count: {}'.format(earlystop_model.tree_count_))\n",
    "print('Early-stopped model validation accuracy: {:.4}'.format(\n",
    "    accuracy_score(y_validation, earlystop_model.predict(X_validation))\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Using Baseline*\n",
    "\n",
    "It is posible to use pre-training results (baseline) for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_params = params.copy()\n",
    "current_params.update({\n",
    "    'iterations': 10\n",
    "})\n",
    "model = CatBoostClassifier(**current_params).fit(X_train, y_train, categorical_features_indices)\n",
    "# Get baseline (only with prediction_type='RawFormulaVal')\n",
    "baseline = model.predict(X_train, prediction_type='RawFormulaVal')\n",
    "# Fit new model\n",
    "model.fit(X_train, y_train, categorical_features_indices, baseline=baseline);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*User Defined Objective Function*\n",
    "\n",
    "It is possible to create your own objective function. Let's create logloss objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoglossObjective(object):\n",
    "    def calc_ders_range(self, approxes, targets, weights):\n",
    "        # approxes, targets, weights are indexed containers of floats\n",
    "        # (containers which have only __len__ and __getitem__ defined).\n",
    "        # weights parameter can be None.\n",
    "        #\n",
    "        # To understand what these parameters mean, assume that there is\n",
    "        # a subset of your dataset that is currently being processed.\n",
    "        # approxes contains current predictions for this subset,\n",
    "        # targets contains target values you provided with the dataset.\n",
    "        #\n",
    "        # This function should return a list of pairs (der1, der2), where\n",
    "        # der1 is the first derivative of the loss function with respect\n",
    "        # to the predicted value, and der2 is the second derivative.\n",
    "        #\n",
    "        # In our case, logloss is defined by the following formula:\n",
    "        # target * log(sigmoid(approx)) + (1 - target) * (1 - sigmoid(approx))\n",
    "        # where sigmoid(x) = 1 / (1 + e^(-x)).\n",
    "        \n",
    "        assert len(approxes) == len(targets)\n",
    "        if weights is not None:\n",
    "            assert len(weights) == len(approxes)\n",
    "        \n",
    "        result = []\n",
    "        for index in range(len(targets)):\n",
    "            e = np.exp(approxes[index])\n",
    "            p = e / (1 + e)\n",
    "            der1 = (1 - p) if targets[index] > 0.0 else -p\n",
    "            der2 = -p * (1 - p)\n",
    "\n",
    "            if weights is not None:\n",
    "                der1 *= weights[index]\n",
    "                der2 *= weights[index]\n",
    "\n",
    "            result.append((der1, der2))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6827074\ttotal: 354ms\tremaining: 3.19s\n",
      "1:\tlearn: 0.6723302\ttotal: 356ms\tremaining: 1.43s\n",
      "2:\tlearn: 0.6619449\ttotal: 357ms\tremaining: 834ms\n",
      "3:\tlearn: 0.6521466\ttotal: 360ms\tremaining: 540ms\n",
      "4:\tlearn: 0.6435227\ttotal: 361ms\tremaining: 361ms\n",
      "5:\tlearn: 0.6353848\ttotal: 362ms\tremaining: 242ms\n",
      "6:\tlearn: 0.6277210\ttotal: 364ms\tremaining: 156ms\n",
      "7:\tlearn: 0.6210282\ttotal: 364ms\tremaining: 91ms\n",
      "8:\tlearn: 0.6141958\ttotal: 365ms\tremaining: 40.6ms\n",
      "9:\tlearn: 0.6073236\ttotal: 367ms\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "model = CatBoostClassifier(\n",
    "    iterations=10,\n",
    "    random_seed=42, \n",
    "    loss_function=LoglossObjective(), \n",
    "    eval_metric=metrics.Logloss()\n",
    ")\n",
    "# Fit model\n",
    "model.fit(train_pool)\n",
    "# Only prediction_type='RawFormulaVal' is allowed with custom `loss_function`\n",
    "preds_raw = model.predict(X_test, prediction_type='RawFormulaVal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Feature Importances*\n",
    "\n",
    "Sometimes it is very important to understand which feature made the greatest contribution to the final result. To do this, the CatBoost model has a get_feature_importance method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex: 59.00409201426859\n",
      "Pclass: 16.34088716974706\n",
      "Ticket: 6.028107169932189\n",
      "Cabin: 3.834724220256021\n",
      "Fare: 3.7129696679343884\n",
      "Age: 3.4844512041824807\n",
      "Parch: 3.3780897403558634\n",
      "Embarked: 2.3139994072899537\n",
      "SibSp: 1.9026794060334498\n",
      "PassengerId: 0.0\n",
      "Name: 0.0\n"
     ]
    }
   ],
   "source": [
    "model = CatBoostClassifier(iterations=50, random_seed=42, logging_level='Silent').fit(train_pool)\n",
    "feature_importances = model.get_feature_importance(train_pool)\n",
    "feature_names = X_train.columns\n",
    "for score, name in sorted(zip(feature_importances, feature_names), reverse=True):\n",
    "    print('{}: {}'.format(name, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Eval Metrics*\n",
    "\n",
    "The CatBoost has a eval_metrics method that allows to calculate a given metrics on a given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f73ff881a0604e00908cacbe929f9fe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = CatBoostClassifier(iterations=50, random_seed=42, logging_level='Silent').fit(train_pool)\n",
    "eval_metrics = model.eval_metrics(validate_pool, [metrics.AUC()], plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Learning Processes Comparison*\n",
    "\n",
    "You can also compare different models learning process on a single plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = CatBoostClassifier(iterations=100, depth=1, train_dir='model_depth_1/', logging_level='Silent')\n",
    "model1.fit(train_pool, eval_set=validate_pool)\n",
    "model2 = CatBoostClassifier(iterations=100, depth=5, train_dir='model_depth_5/', logging_level='Silent')\n",
    "model2.fit(train_pool, eval_set=validate_pool);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a071631fba7741fc9441500cc49ed699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from catboost import MetricVisualizer\n",
    "widget = MetricVisualizer(['model_depth_1', 'model_depth_5'])\n",
    "widget.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameters Tuning**\n",
    "\n",
    "While you could always select optimal number of iterations (boosting steps) by cross-validation and learning curve plots, it is also important to play with some of model parameters, and we would like to pay some special attention to `l2_leaf_reg` and `learning_rate`.\n",
    "\n",
    "We'll select these parameters using the `hyperopt` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperopt\n",
    "\n",
    "def hyperopt_objective(params):\n",
    "    model = CatBoostClassifier(\n",
    "        l2_leaf_reg=int(params['l2_leaf_reg']),\n",
    "        learning_rate=params['learning_rate'],\n",
    "        iterations=500,\n",
    "        eval_metric=metrics.Accuracy(),\n",
    "        random_seed=42,\n",
    "        verbose=False,\n",
    "        loss_function=metrics.Logloss(),\n",
    "    )\n",
    "    \n",
    "    cv_data = cv(\n",
    "        Pool(X, y, cat_features=categorical_features_indices),\n",
    "        model.get_params(),\n",
    "        logging_level='Silent',\n",
    "    )\n",
    "    best_accuracy = np.max(cv_data['test-Accuracy-mean'])\n",
    "    \n",
    "    return 1 - best_accuracy # as hyperopt minimises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params_space = {\n",
    "#     'l2_leaf_reg': hyperopt.hp.qloguniform('l2_leaf_reg', 0, 2, 1),\n",
    "#     'learning_rate': hyperopt.hp.uniform('learning_rate', 1e-3, 5e-1),\n",
    "# }\n",
    "\n",
    "# trials = hyperopt.Trials()\n",
    "\n",
    "# best = hyperopt.fmin(\n",
    "#     hyperopt_objective,\n",
    "#     space=params_space,\n",
    "#     algo=hyperopt.tpe.suggest,\n",
    "#     max_evals=50,\n",
    "#     trials=trials,\n",
    "#     rstate=np.random.default_rng(123)\n",
    "# )\n",
    "\n",
    "# print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More tutorials in the [repo](https://github.com/catboost/tutorials/tree/master)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ysda-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
